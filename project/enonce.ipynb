{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MVA 2023 : Cours Deep et signal, liste des mini projets \n",
    "\n",
    "Le mini-projet est à faire en binômes. Vous pouvez reconstituer des binômes qui ont déjà existé dans les TP. \n",
    "\n",
    "Le mini-projet amène à un notebook jupyter structuré que vous m'enverrez en présenterai lors d'une soutenance d'environ 10 minutes (pas besoin de faire des slides en plus pour la soutenance, vous pourrez dérouler le notebook). \n",
    "\n",
    "Voici une liste de propositions de mini-projets. \n",
    "Vous pouvez proposer votre sujet indépendamment de cette liste ou de modifier un sujet. Dans ce cas validez vos propositions avec moi. \n",
    "\n",
    "L'objectif est de travailler environ 10h sur le projet. \n",
    "Pour chaque sujet vous êtes invités à prendre des initiatives notamment pour \n",
    "- analyser les données (statistiques haut niveau, visualisation, évaluation des difficultés)\n",
    "- partir du cours ou d'un article lié au sujet traité \n",
    "- définir une ou plusieurs métriques d'évaluation\n",
    "- implémenter au moins une et idéalement deux méthodes traitant le problème considéré. Au moins une des deux méthodes est une approche par apprentissage profond. La seconde peut être une approche de traitement du signal classique, une autre architecture de réseau, la même architecture avec une stratégie d'augmentation de données ou d’ingénierie des données... \n",
    "- comparer les approches quantitativement et analyser qualitativement vos résultats, les cas de succès et les cas d'échecs. \n",
    "\n",
    "Si vous n'avez pas abouti à des résultats probants sur cette durée vous êtes invités à analyser de façon critique vos résultats et émettre des hypothèse sur ce qui n'a pas fonctionné (type d'approche, architecture, qualité des données...). \n",
    "Une bonne analyse sera largement valorisée dans l'évaluation. \n",
    "\n",
    "Pour chaque sujet, vous êtes libres d'explorer les pistes qui vous intéressent (tant qu'elles sont raisonnables).\n",
    "Si vous avez des idées originales n'hésitez pas à être créatifs ! \n",
    "\n",
    "\n",
    "## Audio \n",
    "\n",
    "### Denoising\n",
    "Pour ce projet vous avez :\n",
    "\n",
    "Pour le train \n",
    "- Un dossier contenant des fichiers d'enregistrements de voix sans bruit (audio/voice_origin/train)\n",
    "- Un dossier contenant des fichiers d'enregistrements de voix avec une ambiance de rue en arrière-plan (audio/denoising/train)\n",
    "La correspondance entre un enregistrement avec ambiance et l'enregistrement parfait de la voix se fait via le nom des fichiers. \n",
    "\n",
    "Pour l'ensemble de test vous avez deux ensembles de fichiers similaires. \n",
    "\n",
    "Dans audio/voice_origin et audio/denoising vous avec un dossier train_small de petite taille que vous pouvez télécharger rapidement pour faire des essai. \n",
    "\n",
    "L'objectif est d'estimer à partir du signal bruité le signal de voix. \n",
    "\n",
    "Les signaux ont un SNR (Signal to Noise Ratio) compris entre 0 et 20 dB. \n",
    "\n",
    "Vous pouvez au choix travailler \n",
    "- sur le spectrogramme par exemple en vous des approches par masquage présentés dans le cours 09 et en estimant les masques avec un réseau Seq2Seq de votre choix ou un UNet (cf A. Jansson et Al., SINGING VOICE SEPARATION WITH DEEP U-NET CONVOLUTIONAL NETWORK, ISMIR 2017 )\n",
    "- directement sur la forme d'onde  : \n",
    "   - cf D. Stoller  et Al., WAVE-U-NET: A MULTI-SCALE NEURAL NETWORK FOR END-TO-END AUDIO SOURCE SEPARATION, ISMIR 2018\n",
    "   - les apporches TAS NEt : Y. Luo et Al., TaSNet: Time-Domain Audio Separation Network for Real-Time, Single-Channel Speech Separation, ICASSP 2018 ou Y. Luo et Al.,  Conv-tasnet: surpassing ideal time–frequency magnitude masking for speech separation. IEEE/ACM Transactions on Audio, Speech, and Language Processing, 2019.\n",
    "\n",
    "\n",
    "Libre à vous de choisir la fonction de perte utilisée dans l’entraînement et adaptée au format des données que vous utiliserez en entrée du réseau de neurones. \n",
    "\n",
    "Pour l'évaluation des performances sur l'ensemble de test, outre la fonction de perte vous vous intéresserez au PESQ et au STOI des voix estimées.  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Séparation de sources \n",
    "L'objectif de ce projet est d'estimer conjointement la composante voix et la composante bruit d'un enregistrement audio.\n",
    "Pour ce projet vous avez : \n",
    "\n",
    "Pour le train \n",
    "- Un dossier contenant des sous dossier numérotés (exemple 0001 ou 1256)\n",
    "- Dans chaque sous dossier vous avez trois fichiers wav : mix_snr_XX.wav , voice.wav, noise.wav \n",
    "- voice.wav et noise.wav sont les vérités terrain à estimer, mix_snr_XX.wav est le mélange des deux sources avec un SNR de XX pour la composante voix (et de -XX pour la composante bruit) \n",
    "\n",
    "L'ensemble de test est constitué de la même façon. \n",
    "\n",
    "Vous pouvez au choix travailler \n",
    "- sur le spectrogramme par exemple en vous des approches par masquage présentés dans le cours 09 et en estimant les masques avec un réseau Seq2Seq de votre choix ou un UNet (cf A. Jansson et Al., SINGING VOICE SEPARATION WITH DEEP U-NET CONVOLUTIONAL NETWORK, ISMIR 2017 )\n",
    "- avec la méthode Deep Clustering : J.R. Hershey et Al., Deep clustering: Discriminative embeddings for segmentation and separation, ICASSP 2016\n",
    "- directement sur la forme d'onde  : \n",
    "   - cf D. Stoller  et Al., WAVE-U-NET: A MULTI-SCALE NEURAL NETWORK FOR END-TO-END AUDIO SOURCE SEPARATION, ISMIR 2018\n",
    "   - les apporches TAS NEt : Y. Luo et Al., TaSNet: Time-Domain Audio Separation Network for Real-Time, Single-Channel Speech Separation, ICASSP 2018 ou Y. Luo et Al.,  Conv-tasnet: surpassing ideal time–frequency magnitude masking for speech separation. IEEE/ACM Transactions on Audio, Speech, and Language Processing, 2019.\n",
    "\n",
    "Libre à vous de choisir la fonction de perte utilisée dans l’entraînement et adaptée au format des données que vous utiliserez en entrée du réseau de neurones. \n",
    "\n",
    "\n",
    "### Complétion de paquets perdus \n",
    "Lors d'une communication sur IP les échantillons sont envoyés sous forme de paquets. Un paquet a une certaine probabilité d'être perdu ce qui produit un \"trou\" dans le signal reçu. \n",
    "L'objectif de ce projet est de combler les trous dans un signal de voix. \n",
    "\n",
    "Le dataset de train se compose de  : \n",
    "- Un dossier contenant des fichiers d'enregistrements de voix à 8kHz  (audio/voice_origin/train) ; ce sont les données objectifs \n",
    "- Un dossier contenant les fichiers correspondants avec certains paquets qui ont été perdu (audio/packet_loss/train) ; ce sont les données d'entrée à traiter\n",
    "\n",
    "La correspondance entre les deux dossiers pour reconstituer les paires (donnée d'entrée, vérité terrain) se fait par le nom de fichier. \n",
    "Les données de test sont structurées de la même façon. \n",
    "\n",
    "Vous pouvez au choix travailler sur spectrogramme ou directement sur la forme d'onde en vous inspirant par exemple des références données pour la séparation de sources (UNet, WavUnet)\n",
    "\n",
    "Pour ce sujet vous implémenterez nécessairement une approche classique  par exemple en utilisant des interpolations et une méthode à base de réseaux de neurones profonds. \n",
    "\n",
    "Libre à vous de choisir la fonction de perte utilisée dans l’entraînement. \n",
    "Pour l'évaluation des performances sur l'ensemble de test, outre la fonction de perte vous vous intéresserez au PESQ et au STOI des voix estimées.  \n",
    "\n",
    "### Super-résolution \n",
    "L'objectif de ce projet est d'augmenter la définition d'un signal audio échantillonné à 4 kHz vers du 8kHz. \n",
    "\n",
    "Une approche classique consisterait à ajouter un échantillon entre deux échantillons du signal d'origine en interpolant les données (par une constante ou un segment par exemple). \n",
    "On espère qu'un algorithme d'apprentissage pourrait dépasser les performances de cette approche en intégrant de l'information plus globale sur le signal.\n",
    "D'un point de vue spectral, le spectrogramme d'un signal 4 kHz est défini sur l'intervalle de fréquences [0, 2 kHz]. On peut transposer ce spectrogramme sur l'intervalle [0, 4 kHz] qui correspond à un signal 8 kHz en mettant toutes les fréquences entre 2 et 4 kHz à zéros. \n",
    "La tâche que l'on soumet à l'algorithme est alors de deviner les fréquences [2 kHz, 4 kHz] à partir de la partie basse du spectre. \n",
    "Il s'agit donc de compléter des données perdues. \n",
    "\n",
    "Le dataset de train se compose de  : \n",
    "- Un dossier contenant des fichiers d'enregistrements de voix à 8kHz  (audio/voice_origin/train) ; ce sont les données objectifs \n",
    "- Un dossier contenant les fichiers correspondants à 4 kHz (audio/voice_4k/train) ; ce sont les données d'entrée à traiter\n",
    "\n",
    "La correspondance entre les deux dossiers pour reconstituer les paires (donnée d'entrée, vérité terrain) se fait par le nom de fichier. \n",
    "Les données de test sont structurées de la même façon. \n",
    "\n",
    "Vous pouvez au choix travailler sur spectrogramme ou directement sur la forme d'onde en vous inspirant par exemple des références données pour la séparation de sources (UNet, WavUnet)\n",
    "\n",
    "Pour ce sujet vous implémenterez nécessairement une approche classique  par exemple en utilisant des interpolations et une méthode à base de réseaux de neurones profonds. \n",
    "\n",
    "Libre à vous de choisir la fonction de perte utilisée dans l’entraînement. \n",
    "Pour l'évaluation des performances sur l'ensemble de test, outre la fonction de perte vous vous intéresserez au PESQ et au STOI des voix estimées.  \n",
    "\n",
    "## Radar\n",
    "\n",
    "Vous pouvez reprendre les données du TP2 sur la détection de menaces radar que vous avez déjà traités au moyen d'un algorithme d'apprentissage machine (or deep learning) et mettre en place deux approches impliquant des réseaux de neurones profonds. \n",
    "Une difficulté que vous rencontrerez probablement est que le volume de données disponible est relativement faible pour des approches par apprentissage profond. Vous pourrez concentrer une partie de vos efforts pour surmonter cette limitation.\n",
    "\n",
    "## Radio \n",
    "\n",
    "Je vous propose deux sujets dans le prolongement de la classification de séries temporelles par deep learning étudiée dans le TP3. \n",
    "\n",
    "### Détection d'anomalies \n",
    "\n",
    "L'objectif de ce projet est d'être capable dans la phase de test de détecter que certains signaux n'ont pas été vus à l'entrainement. \n",
    "Dans la phase d'entraînement vous partez de l'ensemble train.hdf5 du TP3 qui contient de signaux \n",
    "- labélisés 0, 1, 2, 3, 4, 5 \n",
    "- avec des SNR 30, 20, 10 ou 0 \n",
    "Vous avez en plus pour ce projet un dataset uniquement de test (radio/test_anomalies.hdf5)\n",
    "- avec des signaux des classes 0 à 5 comme vues dans l'ensemble d'entrainement mais aussi avec des signaux de classes 6,7, et 8 qui ne sont PAS représentées dans l'ensemble d'entrainement. \n",
    "\n",
    "L'objectif est de construire un algorithme entraîné sur les classes 0 à 5 et de l'adapter pour qu'il soit capable en test de détecter si un signal a été vu ou non à l'apprentissage. \n",
    "L'objectif en test est donc : \n",
    "- de renvoyer 0 si le signal vient des classes 0 à 5 \n",
    "- de renvoyer 1 sinon \n",
    "Les performances seront évaluées en termes de précision et de recall (cf  mini TP1 ).\n",
    "Toutes les classes de nouveautés peuvent être regroupées dans la même macro classe. Vous pourrez analyser vos résultats conditionnellement à la sous-classe de nouveauté mais il ne vous est pas demandé d'exploité cette information. \n",
    "La décision de cet algorithme pourra dépendre d'un seuil que vous pourrez faire varier. \n",
    "\n",
    "Vous pouvez vous inspirer de ce qui est fait en détection de sons anormaux dans le challenge DCASE : \n",
    "- https://dcase.community/challenge2022/task-unsupervised-anomalous-sound-detection-for-machine-condition-monitoring\n",
    "- https://dcase.community/challenge2023/task-first-shot-unsupervised-anomalous-sound-detection-for-machine-condition-monitoring\n",
    "\n",
    "Vous pouvez aussi essayer d'appliquer des techniques de détection d'outliers ou de nouveautés tels que ceux disponibles dans Scikit-learn \n",
    "https://scikit-learn.org/stable/modules/outlier_detection.html \n",
    "dans un espace latent obtenu par un réseau de neurones profonds. \n",
    " \n",
    "### Few shot learning pour la classification de signaux \n",
    "L'objectif de ce projet est de construire et entraîner un réseau de neurones à identifier des classes avec peu de données. \n",
    "Pour cela je vous propose de partir sur le paradigme enrollment d'une classes et rattachement d'une donnée de test à une classe enrollée présenté dans le cours 09 et par exemple mis en oeuvre dans J. Snell et Al., Prototypical Networks for Few-shot Learning, NIPS 2017. \n",
    "\n",
    "A cet effet vous disposez des datasets suivants : \n",
    "- L'ensemble train.hdf5 du TP3 qui contient des signaux de type 0, 1, 2, 3, 4, 5 que vous pouvez utiliser pour l'entrainement  du réseau\n",
    "- Un ensemble radio/few_shots/enroll.hdf5 qui contient des (quelques) signaux de type 6, 7, 8, 9, 10, 11 ; ce sont les données que vous utiliserez pour enroller les nouvelles classes après l'entraînement \n",
    "- Un ensemble radio/few_shots/test_fewshots.hdf5 qui contient des  signaux de type 6, 7, 8, 9, 10, 11 ; vous testerez sur ces données vos performances de reconnaissance \n",
    "\n",
    "En plus de la méthodologie d'entraînement vous pourrez vous inspirer de la méthodologie d'analyse des performances de l'article de Snell et Al. pour qualifier vos résultats. \n",
    "Vous pourrez notamment mettre en évidence le dépendance des performances au nombre de données utilisées pour enroller les différentes classes. \n",
    "Si vous faites ce travail d'analyse du compromis nombre de données / performances il ne vous est pas demandé de tester une deuxième approche. \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
